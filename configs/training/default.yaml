# Default training configuration
max_epochs: 100
gradient_clip_val: 1.0
accumulate_grad_batches: 1

# Optimizer
optimizer:
    type: "adamw"
    lr: 1e-4
    weight_decay: 1e-4
    betas: [0.9, 0.999]

# Learning rate scheduler
scheduler:
    type: "cosine"
    T_max: 100
    eta_min: 1e-6

# Loss configuration
loss:
    type: "vae" # "vae", "lpips", "biomedclip", "lpips_discriminator"
    recon_loss_type: "mse" # "mse", "l1", "bce"
    kl_weight: 1.0
    recon_weight: 1.0

# Validation
val_check_interval: 1.0
check_val_every_n_epoch: 1

# Logging
log_every_n_steps: 50
save_top_k: 3
